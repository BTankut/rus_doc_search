import os
import streamlit as st
from typing import List, Dict
from langdetect import detect
from more_itertools import chunked
from pathlib import Path
import re
from datetime import datetime
import time
import PyPDF2
import io
from sentence_transformers import SentenceTransformer
import torch
import numpy as np

# Sayfa yapÄ±landÄ±rmasÄ±
st.set_page_config(
    page_title="RusÃ§a DokÃ¼man Arama",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': None,
        'Report a bug': None,
        'About': None
    }
)

# Dark mode CSS
st.markdown("""
<style>
    /* Dark mode renkleri */
    :root {
        --background-color: #1a1a1a;
        --text-color: #ffffff;
        --accent-color: #4CAF50;
    }
    
    /* Ana stil */
    .stApp {
        background-color: var(--background-color);
        color: var(--text-color);
    }
    
    /* Sidebar */
    .css-1d391kg {
        background-color: #2d2d2d;
    }
    
    /* BaÅŸlÄ±klar */
    h1, h2, h3 {
        color: var(--accent-color) !important;
    }
    
    /* Butonlar */
    .stButton>button {
        background-color: var(--accent-color);
        color: white;
        border: none;
        padding: 0.5rem 1rem;
        border-radius: 4px;
    }
    
    /* Metin giriÅŸi */
    .stTextInput>div>div>input {
        background-color: #2d2d2d;
        color: var(--text-color);
        border: 1px solid #444;
    }
    
    /* Dosya yÃ¼kleme */
    .stUploadButton>button {
        background-color: #2d2d2d;
        color: var(--text-color);
        border: 1px solid #444;
    }
    
    /* SonuÃ§ kartlarÄ± */
    .stExpander {
        background-color: #2d2d2d;
        border: 1px solid #444;
    }
</style>
""", unsafe_allow_html=True)

class DocumentSearchSystem:
    def __init__(self):
        self.documents: List[Dict] = []
        self.doc_dir = "documents"
        self.search_history = []
        self.model = None
        self.embeddings = {}
        
        # DokÃ¼man dizinini oluÅŸtur
        os.makedirs(self.doc_dir, exist_ok=True)
        
        # Model yÃ¼kleniyor mesajÄ±
        if not st.session_state.get('model_loaded', False):
            with st.spinner('ğŸ¤– Yapay zeka modeli yÃ¼kleniyor... (Ä°lk aÃ§Ä±lÄ±ÅŸta biraz zaman alabilir)'):
                self.load_model()
                st.session_state.model_loaded = True
    
    def load_model(self):
        """RusÃ§a dil modelini yÃ¼kle"""
        self.model = SentenceTransformer('DeepPavlov/rubert-base-cased-sentence')
        
    def get_embedding(self, text: str) -> np.ndarray:
        """Metin iÃ§in vektÃ¶r oluÅŸtur"""
        return self.model.encode(text, convert_to_tensor=True)
    
    def compute_similarity(self, query_embedding: torch.Tensor, text_embedding: torch.Tensor) -> float:
        """Benzerlik skorunu hesapla"""
        return torch.nn.functional.cosine_similarity(query_embedding.unsqueeze(0), 
                                                   text_embedding.unsqueeze(0)).item()
    
    def extract_pdf_text(self, file) -> str:
        """PDF dosyasÄ±ndan metin Ã§Ä±kar"""
        try:
            pdf_reader = PyPDF2.PdfReader(file)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
            return text
        except Exception as e:
            st.error(f"âŒ PDF okuma hatasÄ±: {str(e)}")
            return ""
        
    def save_document(self, file) -> bool:
        try:
            # Dosya uzantÄ±sÄ±nÄ± kontrol et
            file_ext = Path(file.name).suffix.lower()
            
            if file_ext == '.pdf':
                content = self.extract_pdf_text(file)
                if not content:
                    return False
            elif file_ext == '.txt':
                content = file.read().decode('utf-8')
            else:
                st.warning(f"âš ï¸ {file.name} desteklenmeyen dosya formatÄ±! Sadece .pdf ve .txt dosyalarÄ± kabul edilir.")
                return False
            
            # RusÃ§a kontrolÃ¼
            if detect(content) == 'ru':
                # DosyayÄ± kaydet
                save_path = os.path.join(self.doc_dir, file.name)
                
                # PDF ise orijinal dosyayÄ± kopyala
                if file_ext == '.pdf':
                    file.seek(0)  # Dosya iÅŸaretÃ§isini baÅŸa al
                    with open(save_path, 'wb') as f:
                        f.write(file.read())
                else:
                    with open(save_path, 'w', encoding='utf-8') as f:
                        f.write(content)
                    
                self.documents.append({
                    'name': file.name,
                    'path': save_path,
                    'content': content,
                    'size': len(content.encode('utf-8')),
                    'char_count': len(content),
                    'type': 'PDF' if file_ext == '.pdf' else 'TXT',
                    'upload_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                })
                return True
            else:
                st.warning(f"âš ï¸ {file.name} RusÃ§a deÄŸil!")
                return False
        except Exception as e:
            st.error(f"âŒ Hata: {file.name} dosyasÄ± iÅŸlenirken hata oluÅŸtu - {str(e)}")
            return False
            
    def highlight_text(self, text: str, query: str) -> str:
        """Metinde arama sorgusunu vurgula"""
        if not query:
            return text
            
        pattern = re.compile(f'({re.escape(query)})', re.IGNORECASE)
        return pattern.sub(r'**\1**', text)
            
    def search_documents(self, query: str, chunk_size: int = 500) -> List[Dict]:
        """DokÃ¼manlarda arama yap"""
        if not query.strip():
            return []
            
        # Arama geÃ§miÅŸine ekle
        self.search_history.append({
            'query': query,
            'time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        })
        self.search_history = self.search_history[-5:]  # Son 5 aramayÄ± tut
        
        results = []
        query_embedding = self.get_embedding(query)
        
        for doc in self.documents:
            content = doc['content']
            chunks = list(chunked(content, chunk_size))
            
            for i, chunk in enumerate(chunks):
                chunk_text = ''.join(chunk)
                
                # Chunk'Ä±n vektÃ¶rÃ¼nÃ¼ hesapla veya cache'den al
                chunk_key = f"{doc['name']}_{i}"
                if chunk_key not in self.embeddings:
                    self.embeddings[chunk_key] = self.get_embedding(chunk_text)
                chunk_embedding = self.embeddings[chunk_key]
                
                # Benzerlik skorunu hesapla
                similarity = self.compute_similarity(query_embedding, chunk_embedding)
                
                # Benzerlik skoru 0.5'ten bÃ¼yÃ¼kse sonuÃ§lara ekle
                if similarity > 0.5:
                    results.append({
                        'document': doc['name'],
                        'text': chunk_text,
                        'similarity': similarity,
                        'chunk_index': i,
                        'size': doc['size'],
                        'char_count': doc['char_count'],
                        'type': doc.get('type', 'TXT')
                    })
        
        # Benzerlik skoruna gÃ¶re sÄ±rala
        results.sort(key=lambda x: x['similarity'], reverse=True)
        return results[:10]  # En iyi 10 sonucu dÃ¶ndÃ¼r

def format_size(size_bytes: int) -> str:
    """Boyutu okunabilir formata Ã§evir"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size_bytes < 1024:
            return f"{size_bytes:.1f} {unit}"
        size_bytes /= 1024
    return f"{size_bytes:.1f} TB"

def main():
    # BaÅŸlÄ±k ve versiyon gÃ¶stergesi
    col1, col2 = st.columns([4, 1])
    with col1:
        st.title("ğŸ” RusÃ§a DokÃ¼man Arama Sistemi")
    with col2:
        st.markdown("""
        <div style='background-color: #4CAF50; padding: 10px; border-radius: 5px; text-align: center;'>
            <span style='color: white; font-weight: bold;'>ğŸ“± Streamlit v1.41.1</span>
        </div>
        """, unsafe_allow_html=True)
    
    # Browser kapatÄ±ldÄ±ÄŸÄ±nda uygulamayÄ± sonlandÄ±r
    if not st.session_state.get("browser_connected"):
        st.session_state.browser_connected = True
        st.session_state.connection_time = time.time()
    
    # Her 5 saniyede bir baÄŸlantÄ±yÄ± kontrol et
    if time.time() - st.session_state.connection_time > 5:
        st.session_state.connection_time = time.time()
        if not st.session_state.browser_connected:
            st.stop()
            os._exit(0)
    
    # Oturum durumunu baÅŸlat
    if 'search_system' not in st.session_state:
        st.session_state.search_system = DocumentSearchSystem()
    
    # Sol sidebar
    with st.sidebar:
        st.header("ğŸ“ DokÃ¼man YÃ¶netimi")
        
        # Dosya yÃ¼kleme
        uploaded_files = st.file_uploader(
            "RusÃ§a metin dosyalarÄ±nÄ± yÃ¼kleyin (.txt, .pdf)",
            type=['txt', 'pdf'],
            accept_multiple_files=True
        )
        
        if uploaded_files:
            success_count = 0
            for file in uploaded_files:
                if st.session_state.search_system.save_document(file):
                    success_count += 1
            
            if success_count > 0:
                st.success(f"âœ… {success_count} RusÃ§a dokÃ¼man baÅŸarÄ±yla yÃ¼klendi!")
        
        # YÃ¼klÃ¼ dokÃ¼manlar
        st.subheader("ğŸ“š YÃ¼klÃ¼ DokÃ¼manlar")
        for doc in st.session_state.search_system.documents:
            st.markdown(f"""
            â€¢ **{doc['name']}** ({doc['type']})  
            _{format_size(doc['size'])} | {doc['char_count']} karakter_  
            YÃ¼kleme: {doc['upload_time']}
            """)
        
        # Arama geÃ§miÅŸi
        if st.session_state.search_system.search_history:
            st.subheader("ğŸ•’ Arama GeÃ§miÅŸi")
            for history in reversed(st.session_state.search_system.search_history[-5:]):
                st.markdown(f"""
                ğŸ” _{history['query']}_  
                {history['time']}
                """)
    
    # Ana iÃ§erik
    st.header("ğŸ” Arama")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        query = st.text_input(
            "Arama sorgusu (RusÃ§a):",
            placeholder="Aramak istediÄŸiniz metni girin..."
        )
    
    with col2:
        chunk_size = st.number_input(
            "ParÃ§a boyutu:",
            min_value=100,
            max_value=1000,
            value=500,
            step=100
        )
    
    if query:
        results = st.session_state.search_system.search_documents(query, chunk_size)
        
        if not results:
            st.warning("âš ï¸ SonuÃ§ bulunamadÄ±.")
        else:
            st.success(f"âœ¨ {len(results)} sonuÃ§ bulundu!")
            
            for i, result in enumerate(results, 1):
                with st.expander(
                    f"ğŸ“„ SonuÃ§ {i} - {result['document']} "
                    f"(ParÃ§a {result['chunk_index'] + 1})"
                ):
                    st.markdown(f"""
                    {result['text']}
                    
                    ---
                    ğŸ“Š _DokÃ¼man boyutu: {format_size(result['size'])} | {result['char_count']} karakter_
                    """)

if __name__ == "__main__":
    main()
